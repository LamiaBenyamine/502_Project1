---
title: "ST502: Project 1"
author: "Ming Cai & Lamia Benyamine"
date: "2024-10-08"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

# INTRODUCTION

There are many methods to approximate the probability of success, p,
from a Binomial random sample, however, not all have the same coverage
probabilities or average length of the confidence interval. This report
will review several different methods using R and compare the
performance of the confidence intervals for various sample sizes and
probabilities for these three properties:

-   The proportion of intervals that capture the true value

-   The proportion that miss above and proportion that miss below

-   The average length of the interval

We will use data collected from 1,00 random samples from a binomial
distribution where n varies from 15, 13, to 100 and p varies from 0.01
to 0.99 across each approximation method. The methods reviewed in this
report are:

-   Wald interval

-   Adjusted Wald interval

-   Clopper-Pearson (exact) interval

-   Score interval

-   Raw percentile interval using a parametric bootstrap

-   Bootstrap t interval using a parametric bootstrap.

# SIMULATION METHODS

***Note: We will use*** $\alpha = 0.05$ ***as default in all
calculations.*** Also, ***for all methods, when*** $y = 0$***, we set
the interval to be*** $[0,0]$ ***and when*** $y = n$***, we set the
interval to be*** $[1,1]$***.***

## Wald Interval

The formula for calculating the Wald confidence interval is:

$$
\hat{p} - z_{1-\frac{\alpha}{2}}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} < p < \hat{p} + z_{1-\frac{\alpha}{2}}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}},
$$

To calculate the Wald interval for a proportation $p$, we need three key components: the sample proportion $\hat{p}$, the sample size $n$ and the desired confidence level $1-\alpha$. The value $z_c$ represents the critical value corresponding to the c-th quantile of the standard normal distribution.

The formular for calculating the Wald Interval is:

```{r}
WaldCI <- function(y, n, alpha = 0.05){
 # Initialize vectors to store lower and upper intervals
  lower_intervals <- numeric(length(y))
  upper_intervals <- numeric(length(y))
 
  # Loop through each success value
  for (i in seq_along(y)) {
      # Estimate of the probability of success
      p_hat = y[i]/n  
    # Special cases for y = 0 or y = n
    if (y[i] == 0) {
      lower_intervals[i] <- 0
      upper_intervals[i] <- 0  
    } else if (y[i] == n) {
      lower_intervals[i] <- 1
      upper_intervals[i] <- 1
    } else {
      # Calculate the Wald CI
      lower_intervals[i] <- p_hat - qnorm(1-alpha/2)*sqrt((p_hat*(1-p_hat))/n)
      upper_intervals[i] <- p_hat + qnorm(1-alpha/2)*sqrt((p_hat*(1-p_hat))/n)
    }
  }
  # Return the lists of lower and upper intervals
  return(list(Lower = lower_intervals, Upper = upper_intervals))
}
```

## Adjusted Wald interval

To address the limitations of the Wald interval's performance, the adjusted Wald interval was introduced. The formula is nearly identical to that of the Wald interval, but with a modification: 2 successes and 2 failures are added to the sample data set.

$$
\tilde{p} - z_{1-\frac{\alpha}{2}}\sqrt{\frac{\tilde{p}(1-\tilde{p})}{n}} < p < \tilde{p} + z_{1-\frac{\alpha}{2}}\sqrt{\frac{\tilde{p}(1-\tilde{p})}{n}},
$$

where $\tilde{p} = (Y+2)/(n+4)$.

The formular for calculating the Adjusted Wald Interval is:

```{r}
AdjWaldCI <- function(y, n, alpha = 0.05) {
 # Initialize vectors to store lower and upper intervals
  lower_intervals <- numeric(length(y))
  upper_intervals <- numeric(length(y))
  
  # Loop through each success value
  for (i in seq_along(y)) {
    # Calculate adjusted estimate of probability of success
    p_tilde <- (y[i] + 2) / (n + 4)

    # Special cases for y = 0 or y = n
    if (y[i] == 0) {
      lower_intervals[i] <- 0
      upper_intervals[i] <- 0  
    } else if (y[i] == n) {
      lower_intervals[i] <- 1
      upper_intervals[i] <- 1
    } else {
      # Calculate the adjusted Wald CI
      lower_intervals[i] <- p_tilde - qnorm(1 - alpha / 2) * sqrt((p_tilde * (1 - p_tilde)) / (n + 4))
      upper_intervals[i] <- p_tilde + qnorm(1 - alpha / 2) * sqrt((p_tilde * (1 - p_tilde)) / (n + 4))
    }
  }
  # Return the lists of lower and upper intervals
  return(list(Lower = lower_intervals, Upper = upper_intervals))
}
```

## Clopper-Pearson (exact) interval

The Clopper-Pearson interval, often an "exact" interval ensures that the coverage probability is at least
for any $1 - \alpha$ for any value of $p$. The confidence interval is:

$$
\left[ 1 + \frac{n-y+1}{yF_{2y,2(n-y+1),\frac{\alpha}{2}}} \right]^{-1} < p < \left[ 1 + \frac{n-y}{(y+1)F_{2(y+1),2(n-y),1-\frac{\alpha}{2}}} \right]^{-1},
$$

the $F_{a,b,c}$ denotes the $c$ quantile from the F distribution with degrees of freedom $a$ and $b$.

The formular for calculating the Clopper-Pearson interval is:

```{r}
ClopperPearsonCI <- function(y, n, alpha = 0.05){
 # Initialize vectors to store lower and upper intervals
  lower_intervals <- numeric(length(y))
  upper_intervals <- numeric(length(y))
 
  # Loop through each success value
  for (i in seq_along(y)) {
    
   # Special cases for y = 0 or y = n
    if (y[i] == 0) {
      lower_intervals[i] <- 0
      upper_intervals[i] <- 0
    } else if (y[i] == n) {
      lower_intervals[i] <- 1
      upper_intervals[i] <- 1
    } else {
      # Calculate the general case for Clopper-Pearson CI using F-distribution
      lower_intervals[i] <- 1 / (1 + ((n-y[i]+1) / (y[i] * qf(alpha/2, 2*y[i], 2*(n-y[i]+1))))) 
      upper_intervals[i] <- 1 / (1 + ((n-y[i]) / ((y[i]+1) * qf(1-(alpha/2), 2*(y[i]+1), 2*(n-y[i])))))
    }
  }
 # Return the lists of lower and upper intervals
  return(list(Lower = lower_intervals, Upper = upper_intervals))
}
```

## Score interval

Score tests, including their standard errors, are derived from the log-likelihood evaluated at the parameter's null hypothesis value. In contrast, Wald tests are based on the log-likelihood evaluated at the maximum likelihood estimate. The score interval is applicable to a wide range of sample sizes and $p$ values. The formula is:

$$
\frac{\hat{p}+\frac{z_{1-\frac{\alpha}{2}}^2}{2n}-z_{1-\frac{\alpha}{2}}\sqrt{\frac{\hat{p}(1-\hat{p}) + \frac{z_{1-\frac{\alpha}{2}}^2}{4n}}{n}}}{1+\frac{z_{1-\frac{\alpha}{2}}^2}{n}} < p < \frac{\hat{p}+\frac{z_{1-\frac{\alpha}{2}}^2}{2n}+z_{1-\frac{\alpha}{2}}\sqrt{\frac{\hat{p}(1-\hat{p}) + \frac{z_{1-\frac{\alpha}{2}}^2}{4n}}{n}}}{1+\frac{z_{1-\frac{\alpha}{2}}^2}{n}},
$$

here the $z_c$ represents the critical value corresponding to the c-th quantile of the standard normal distribution. 

The formula for calculating the Score interval is:

```{r}
ScoreCI <- function(y, n, alpha = 0.05){
  # Z-score for the desired confidence level
  z = qnorm(1-alpha/2) 
  # Initialize vectors to store lower and upper intervals
  lower_intervals <- numeric(length(y))
  upper_intervals <- numeric(length(y))
 
  # Loop through each success value
  for (i in seq_along(y)) {
    # Estimate of the probability of success
    p_hat = y[i]/n  
    # Special cases for y = 0 or y = n
    if (y[i] == 0) {
      lower_intervals[i] <- 0
      upper_intervals[i] <- 0  
    } else if (y[i] == n) {
      lower_intervals[i] <- 1
      upper_intervals[i] <- 1
    } else {
      # Calculate the Score CI
      lower_intervals[i] <- 
      (p_hat + z^2/(2*n) - z*sqrt((p_hat*(1-p_hat) + z^2/(4*n))/n)) / (1 + z^2/n)
      upper_intervals[i] <-
      (p_hat + z^2/(2*n) + z*sqrt((p_hat*(1-p_hat) + z^2/(4*n))/n)) / (1 + z^2/n)
    }
  }
  # Return the lists of lower and upper intervals
  return(list(Lower = lower_intervals, Upper = upper_intervals))
}
```

## Raw percentile interval and Bootstrap t interval function (both using a parametric bootstrap)

To calculate the Raw percentile interval, we need to find the $\frac{\alpha}{2}$ quantile and the $1-\frac{\alpha}{2}$ quantile of the
$\hat{p}$ of of the sample proportions $p$.

$$
\hat{p}_{\frac{\alpha}{2}} < p < \hat{p}_{1-\frac{\alpha}{2}} 
$$

here the $\hat{p}_{c}$ represents the $c$ quantile of the proportion of the samples.

To find the Bootstrap t interval, we use following steps:

1.  Calculate the mean of our sample's $\hat{p}$ to generate
    bootstrapped $\hat{p}_{boot}$,

2.  Use the mean of bootstrapped $\hat{p}_{boot}$ to generate secondary
    bootstrapped $\hat{p}_{boot2}$,

3.  Use secondary bootstrapped $\hat{p}_{boot2}$ to find the estimated
    standard error of $\hat{p}_{boot}$,

4.  Calculate the interval based on formula.

$$
\hat{p} - t_{1-{\frac{\alpha}{2}}}\cdot \hat{SE} < p < \hat{p} - t_{\frac{\alpha}{2}}\cdot \hat{SE}
$$

where the $t_{c}$ denotes the $c$ quantile of the bootstrapped t values,
and

$$
T = \frac{\underset{\sim}{\hat{p}}-p}{\underset{\sim}{\hat{SE}}(\underset{\sim}{\hat{p}})}
$$

The function for finding the Raw percentile interval and the Bootstrap t
interval is given below:

```{r}
BootstrapCI <- function(y, n, B, alpha = 0.05) {
  # Initialize vectors to store lower and upper intervals
  raw_lower <- numeric(length(y))
  raw_upper <- numeric(length(y))
  boot_t_interval_low <- numeric(length(y))
  boot_t_interval_up <- numeric(length(y))

  set.seed(4321)
  # Loop through each success value
  for (i in seq_along(y)) {
      # Estimate the proportion
      p_hat <- y[i] / n

      # Bootstrap t interval calculations
      boot_estimates <- replicate(B, {
      sim_data <- rbinom(1, n, prob = p_hat)  # Generate bootstrap sample
      p_hat_boot <- sim_data / n  # Bootstrap estimate of proportion

      # Return NA if p_hat_boot is 0 or 1
      if (p_hat_boot == 0 || p_hat_boot == 1) {
        return(c(NA, NA))
      }
      # Perform secondary bootstrap for standard error estimation
      B2 <- 50
      secondary_boot <- replicate(B2, {
        sim_data2 <- rbinom(1, n, prob = p_hat_boot)  # Second bootstrap sample
        p_hat_boot2 <- sim_data2 / n  # Bootstrap estimate
        return(p_hat_boot2)
      })

      # Find SE for t-stat
      estimated_SE_p_hat_boot <- sd(secondary_boot)  # Standard error
      if (estimated_SE_p_hat_boot == 0) return(c(NA, NA))  # Handle division by zero

      # Calculate t-statistic
      p_boot_t <- (p_hat_boot - p_hat) / estimated_SE_p_hat_boot
      return(c(p_hat_boot, p_boot_t))
    })

    # Calculate raw percentile interval from bootstrap samples
    raw_lower[i] <- quantile(boot_estimates[1, ], alpha / 2, na.rm = TRUE)
    raw_upper[i] <- quantile(boot_estimates[1, ], 1 - alpha / 2, na.rm = TRUE)

    # Filter out invalid p_hat_boot and infinite t-statistics
    valid_boot_est <- na.omit(boot_estimates[1, ])
    valid_t_stat <- boot_estimates[2, is.finite(boot_estimates[2, ])]
    
    # Calculate the t-bootstrap intervals using quantiles of valid t-stats
    boot_t_interval_low[i] <- p_hat - quantile(valid_t_stat, 1 - alpha / 2, na.rm = TRUE) * sd(valid_boot_est)
    boot_t_interval_up[i] <- p_hat - quantile(valid_t_stat, alpha / 2, na.rm = TRUE) * sd(valid_boot_est)
  }
  
  # combine intervals into one list
  raw_interval <- list(Lower = raw_lower, Upper = raw_upper)
  t_interval <- list(Lower = boot_t_interval_low, Upper = boot_t_interval_up)

  # Return both raw percentile and t-bootstrap intervals
  return(list(raw_boot = raw_interval, t_boot = t_interval))
}
```

## Creation of Data

We generated $N = 1000$ random samples from a binomial distribution
where sample size $n$ varies across 15, 30, to 100 and true proportion
$p$ varies from 0.01 to 0.99 (15 total values of p).

```{r}
# Set values
N <- 1000 # Number of random samples
n <- c(15, 30, 100) # Values of n
p <- seq(0.01, 0.99, length.out = 15) # Values of p

# Set seed to allow for replication of data
set.seed(4321) 
# Function to generate random binomial sample data for each combination of n and p
GetData <- function(n_vals, p_vals, N = N) { 
  # Initialize a list to store sample data
  sample_data <- list()  
  for (n in n_vals) {
    for (p in p_vals) {
      samples <- rbinom(N, size = n, prob = p)  # Generate N binomial samples
      col_name <- paste0("n", n, "p", p)  # Create column name for the dataset
      sample_data[[col_name]] <- samples  # Store samples in the list
    }
  }
  return(sample_data)
}
sample_data <- GetData(n, p, N)
```

## Execute the Monte Carlo simulation

### Wald Simulation

```{r}
# Initialize a data frame to store the results
waldci_results <- data.frame()

for (col_name in names(sample_data)) {
    samples <- sample_data[[col_name]]  # Get the samples
    # Extract the n and p values from the column name
    n_value <- as.numeric(sub("n(\\d+)p.*", "\\1", col_name))
    true_p <- as.numeric(sub(".*p(\\d+\\.\\d+)", "\\1", col_name))
    
    # Compute the CI
    ci <- WaldCI(samples, n_value)
    
    # Store results
    waldci_results <- rbind(waldci_results, data.frame(
      Method = "Wald",
      Sample = col_name,
      True_P = true_p,
      Size = n_value,
      # Check if the true p value is within the CI
      Coverage_rate = mean((ci[[1]] <= true_p) & (ci[[2]] >= true_p)), 
      Miss_Above = mean((ci[[2]] < true_p)),  # True p is above CI
      Miss_Below = mean((ci[[1]] > true_p)),   # True p is below CI
      Width = mean(ci[[2]] - ci[[1]]) # Width of interval
  ))
}
# Aggregate by taking the average of the properties 
Wald_Properties <- aggregate(cbind(Coverage_rate, Miss_Above, Miss_Below, Width) ~ Size, data = waldci_results, FUN = mean)
```

### Adjusted Wald Simulation

```{r}
# Initialize a data frame to store the results
adjwaldci_results <- data.frame()

for (col_name in names(sample_data)) {
    samples <- sample_data[[col_name]]  # Get the samples
    # Extract the n and p values from the column name
    n_value <- as.numeric(sub("n(\\d+)p.*", "\\1", col_name))
    true_p <- as.numeric(sub(".*p(\\d+\\.\\d+)", "\\1", col_name))
    
    # Compute the CI
    ci <- AdjWaldCI(samples, n_value)
    
    # Store results
    adjwaldci_results <- rbind(adjwaldci_results, data.frame(
      Method = "ADJWald",
      Sample = col_name,
      True_P = true_p,
      Size = n_value,
      # Check if the true p value is within the CI
      Coverage_rate = mean((ci[[1]] <= true_p) & (ci[[2]] >= true_p)), 
      Miss_Above = mean((ci[[2]] < true_p)),  # True p is above CI
      Miss_Below = mean((ci[[1]] > true_p)),   # True p is below CI
      Width = mean(ci[[2]] - ci[[1]]) # Width of interval
  ))
}
# Aggregate by taking the average of the properties 
Adj_Wald_Properties <- aggregate(cbind(Coverage_rate, Miss_Above, Miss_Below, Width) ~ Size, data = adjwaldci_results, FUN = mean)
```

### Clopper Pearson Simulation

```{r}
# Initialize a data frame to store the results
cpci_results <- data.frame()

for (col_name in names(sample_data)) {
    samples <- sample_data[[col_name]]  # Get the samples
    # Extract the n and p values from the column name
    n_value <- as.numeric(sub("n(\\d+)p.*", "\\1", col_name))
    true_p <- as.numeric(sub(".*p(\\d+\\.\\d+)", "\\1", col_name))
    
    # Compute the CI
    ci <- ClopperPearsonCI(samples, n_value)
    
   # Store results
    cpci_results <- rbind(cpci_results, data.frame(
      Method = "CP",
      Sample = col_name,
      True_P = true_p,
      Size = n_value,
      # Check if the true p value is within the CI
      Coverage_rate = mean((ci[[1]] <= true_p) & (ci[[2]] >= true_p)), 
      Miss_Above = mean((ci[[2]] < true_p)),  # True p is above CI
      Miss_Below = mean((ci[[1]] > true_p)),   # True p is below CI
      Width = mean(ci[[2]] - ci[[1]]) # Width of interval
  ))
}
# Aggregate by taking the average of the properties 
CP_Properties <- aggregate(cbind(Coverage_rate, Miss_Above, Miss_Below, Width) ~ Size, data = cpci_results, FUN = mean)
```

### Score Interval Simulation

```{r}
# Initialize a data frame to store the results
scoreci_results <- data.frame()

# Loop through each sample in sample_data to compute CIs
for (col_name in names(sample_data)) {
  samples <- sample_data[[col_name]]  # Get the samples
  # Extract the n and p values from the column name
  n_value <- as.numeric(sub("n(\\d+)p.*", "\\1", col_name))
  true_p <- as.numeric(sub(".*p(\\d+\\.\\d+)", "\\1", col_name))
  
  # Compute the CI
  ci <- ScoreCI(samples, n_value)
  
  # Store results
  scoreci_results <- rbind(scoreci_results, data.frame(
    Method = "Score",
    Sample = col_name,
    True_P = true_p,
    Size = n_value,
    # Check if the true p value is within the CI
    Coverage_rate = mean((ci[[1]] <= true_p) & (ci[[2]] >= true_p)),
    Miss_Above = mean((ci[[2]] < true_p)),  # True p is above CI
    Miss_Below = mean((ci[[1]] > true_p)),   # True p is below CI
    Width = mean(ci[[2]] - ci[[1]]) # Width of interval
  ))
}
# Aggregate by taking the average of the properties 
Score_Properties <- aggregate(cbind(Coverage_rate, Miss_Above, Miss_Below, Width) ~ Size, data = scoreci_results, FUN = mean)
```

### Bootstrap Interval Simulation (Raw percentile & t-interval)

```{r}
# Initialize a data frame to store the results and set the replication values
raw_bootci_results <- data.frame()
t_bootci_results <- data.frame()
B = 100
B2 = 50

# Loop through each sample in sample_data to compute CIs
for (col_name in names(sample_data)) {
  samples <- sample_data[[col_name]]  # Get the samples
  # Extract the n and p values from the column name
  n_value <- as.numeric(sub("n(\\d+)p.*", "\\1", col_name))
  true_p <- as.numeric(sub(".*p(\\d+\\.\\d+)", "\\1", col_name))
  
  # Compute the CI
  ci <- BootstrapCI(samples, n_value, B)

    # Store results for raw percentile bootstrap method
  raw_bootci_results <- rbind(raw_bootci_results, data.frame(
    Method = "Raw-boot",
    Sample = col_name,
    True_P = true_p,
    Size = n_value,
    # Check if the true p value is within the CI
    Coverage_rate = mean((ci[[1]][[1]] <= true_p) & (ci[[1]][[2]] >= true_p)), 
    Miss_Above = mean((ci[[1]][[2]] < true_p)),  # True p is above CI
    Miss_Below = mean((ci[[1]][[1]] > true_p)),   # True p is below CI
    Width = mean(ci[[1]][[2]] - ci[[1]][[1]]) # Width of interval
  ))
  
    # Store results for t-interval bootstrap method
  t_bootci_results <- rbind(t_bootci_results, data.frame(
    Method = "t-interval",
    Sample = col_name,
    True_P = true_p,
    Size = n_value,
    # Check if the true p value is within the CI
    Coverage_rate = mean((ci[[2]][[1]] <= true_p) & (ci[[2]][[2]] >= true_p)), 
    Miss_Above = mean((ci[[2]][[2]] < true_p)),  # True p is above CI
    Miss_Below = mean((ci[[2]][[1]] > true_p)),   # True p is below CI
    Width = mean(ci[[2]][[2]] - ci[[2]][[1]]) # Width of interval
  ))
}
# Aggregate by taking the average of the properties 
Raw_Boot_Properties <- aggregate(cbind(Coverage_rate, Miss_Above, Miss_Below, Width) ~ Size, data = raw_bootci_results, FUN = mean)
t_Interval_Boot_Properties <- aggregate(cbind(Coverage_rate, Miss_Above, Miss_Below, Width) ~ Size, data = t_bootci_results, FUN = mean)
```

# RESULTS

## Summary Table

Combining the results from the properties of all the above methods into
a table.

```{r, warning = FALSE, message = FALSE}
# Add an attribute column
Wald_Properties$Method <- "Wald"
Adj_Wald_Properties$Method <- "AdjWald"
CP_Properties$Method <- "CP"
Score_Properties$Method <- "Score"
Raw_Boot_Properties$Method <- "Raw-% boot"
t_Interval_Boot_Properties$Method <- "t-int boot"

library(dplyr)
# Combine all tables into one
combined_properties <- arrange(rbind(Wald_Properties, Adj_Wald_Properties, CP_Properties, Score_Properties, Raw_Boot_Properties, t_Interval_Boot_Properties), Size)
combined_properties
```

## Coverage Probability Grid

This is a Comparison of Coverage Probabilities for the alpha 95% Wald,
Adjusted Wald, Clopper-Pearson, Score, and Bootstrap Intervals for each
sample size.

```{r, warning = FALSE, message = FALSE}
library(ggplot2)
library(tidyr)
#combine all the CI results to get the coverage probability by p value
combined_results <- rbind(waldci_results, adjwaldci_results, cpci_results, scoreci_results, raw_bootci_results, t_bootci_results)

# Set the order of Method as a factor
combined_results$Method <- factor(combined_results$Method, levels = c("Wald", "ADJWald", "CP", "Score", "Raw-boot", "t-interval"))

# Create the line graph for Coverage Probability
combined_results |>
ggplot(aes(x = True_P, y = Coverage_rate)) +
  geom_line(size = 0.5) + 
  labs(title = "Average Coverage Probability by Sample Size and Method") +
  facet_grid(Size ~ Method) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "red") + 
  coord_cartesian(ylim = c(0, 1)) + # Set y-axis limits from 0 to 1
  theme_bw() +
  theme(  # Remove major & minor grid lines and keep borders.Update x-axis label to avoid overlap
    panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(color = "black"), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 8), axis.title.x = element_blank(), axis.title.y = element_blank())
```

## Interval Length Grid

This is a Comparison of interval lengths for the alpha 95% Wald,
Adjusted Wald, Clopper-Pearson, Score, and Bootstrap Intervals for each
sample size.

```{r, warning = FALSE, message = FALSE}
# Create the line graph for Interval Length
combined_results |>
ggplot(aes(x = True_P, y = Width)) +
  geom_line(size = 0.5) + 
  labs(title = "Average Interval Length by Sample Size and Method") +
  facet_grid(Size ~ Method) +
  theme_bw() +
  theme(  # Remove major & minor grid lines and keep borders.Update x-axis label to avoid overlap
    panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(color = "black"), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 8), axis.title.x = element_blank(), axis.title.y = element_blank())
```

### Standard Error of Interval Widths

```{r}
# Calculate average interval length and standard error
average_lengths <- combined_results |>
  group_by(Size, Method) |>
  summarise(
    Avg_Width = mean(Width, na.rm = TRUE),
    SE_Width = sd(Width, na.rm = TRUE) / sqrt(n()), .groups = 'drop') |>
  pivot_wider(
    names_from = Size,
    values_from = c(Avg_Width, SE_Width))
average_lengths
```

## Review Results

The observed coverage began to get closer to the expected 0.95 level as
the sample size grew. The Average Coverage Probability grid shows the
coverage rate steadies out as the sizse grows, so there is less
variability. We do see an improvement between the Wald and the Adjusted
Wald intervals, but the t-interval bootstrap  has the highest
coverage probability with 0.94 and Wald with the lowest at 0.89 for
sample size 100. The Average Interval Length grid illustrates the
interval lengths decreasing as n grows, with the Raw Percentile
Bootstrap having the smallest interval length on average and
t-interval having the largest for n = 100. Both bootstrap intervals
have the lowest standard error of 0.03 and Wald the lowest again with
a standard error of 0.014 for the average interval length of size 100.
In the smallest sample size the t-interval Bootstrap has the highest
coverage probability, but it has the widest interval length on average.

# CONCLUSION

Rank the coverage probabilities and the interval lengths by method to
find an overall best method.

```{r}
ranked_prop <- combined_properties |>
  group_by(Size) |>
  arrange(desc(Coverage_rate)) |>
  mutate(Coverage_Rank = row_number()) |>
  arrange(Width) |>
  mutate(length_Rank = row_number()) 

avg_ranks_by_method <- ranked_prop |>
  group_by(Method) |>
  summarise(
    Avg_Coverage_Rank = mean(Coverage_Rank, na.rm = TRUE),
    Avg_Length_Rank = mean(length_Rank, na.rm = TRUE), .groups = 'drop')

# Now average those averages for a final ranking
final_avg_ranks <- avg_ranks_by_method |>
  group_by(Method) |>
  summarise(Overall_Avg_Rank = mean(c(Avg_Coverage_Rank, Avg_Length_Rank)), .groups = 'drop') |>
  arrange(Overall_Avg_Rank)
final_avg_ranks
```

Based on these results, the Score interval  has the overall best results across all sample sizes. There are other more complex methods for creating confidence intervals that could be tested, along with increasing the number of samples that are taken for each method and size.
